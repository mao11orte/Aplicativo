import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from groq import Groq
import streamlit as st

# Descargar los recursos necesarios de NLTK si no los tienes
nltk.download('punkt')

# Inicializar el cliente de Groq
client = Groq(api_key="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")

# Funci贸n para cargar datos de archivos .xlsx
def load_xlsx(file_path):
    return pd.read_excel(file_path)

st.set_page_config(
    page_title="Datos Quind铆o",
    layout="centered", # Forma de layout ancho o compacto
)

# Funci贸n para obtener la respuesta de la IA
def get_ai_response(messages):
    completion = client.chat.completions.create(
        model="llama-3.1-70b-versatile",
        messages=messages,
        temperature=0.2,
        max_tokens=512,
        stream=True,
    )
    response = "".join(chunk.choices[0].delta.content or "" for chunk in completion)
    return response

# Funci贸n para buscar en los datos cargados
def search_in_data(query, dataframe):
    result = []
    
    # Asegurarse de que el query no sea vac铆o
    if not query.strip():
        return result
    
    # Buscar el query en todas las columnas de la tabla
    for column in dataframe.columns:
        # Si la columna es de tipo string (objeto), usar str.contains
        if dataframe[column].dtype == 'object':
            # Filtramos las filas donde la columna no es NaN y aplicamos str.contains
            valid_rows = dataframe[column].dropna()
            result += dataframe[valid_rows.str.contains(query, case=False, na=False)].values.tolist()
        
        # Si la columna es de tipo num茅rico (int o float), buscar coincidencias num茅ricas
        elif pd.api.types.is_numeric_dtype(dataframe[column]):
            # Verificar si la consulta es un n煤mero y buscarlo en la columna
            try:
                numeric_query = float(query)  # Intentamos convertir el query a n煤mero
                matching_rows = dataframe[dataframe[column] == numeric_query]
                result += matching_rows.values.tolist()  # A帽adimos los resultados encontrados
            except ValueError:
                # Si no se puede convertir el query a n煤mero, simplemente lo ignoramos
                pass
    
    return result

# Funci贸n para procesar el query (min煤sculas y tokenizaci贸n)
def process_query(query):
    query_lower = query.lower()  # Convertimos a min煤sculas
    try:
        query_tokens = word_tokenize(query_lower)  # Tokenizamos el query
    except Exception as e:
        print(f"Error al tokenizar: {e}")
        query_tokens = query_lower.split()  # Si falla, dividimos en espacios
    return " ".join(query_tokens)  # Retornamos el query tokenizado

# Funci贸n para reiniciar el chat al cambiar de categor铆a
def reiniciar_chat():
    """Reinicia el historial del chat cuando se selecciona una nueva categor铆a."""
    st.session_state['messages'] = []  # Limpiar el historial de mensajes
    st.session_state['dataframe'] = None  # Limpiar el dataframe
    st.session_state['current_category'] = None  # Limpiar la categor铆a actual

# Funci贸n principal del chat
def chat():
    st.title("Informaci贸n Departamento del Quind铆o")
    st.write("Bienvenido a tu asistente de informaci贸n de tu departamento.")

    if 'messages' not in st.session_state:
        st.session_state['messages'] = []

    # Categor铆as y archivos
    categories = {
        "Cultivos": "EVAS_Quindio.xlsx",
        "Poblaci贸n Vulnerable": "IPM_Quindio.xlsx",
        "Datos socioecon贸micos": "Socioeconomico_Quindio.xlsx",
        "Informaci贸n general": "datos_quindio_generales.xlsx"
    }

    # Selector de categor铆a
    category = st.selectbox("Selecciona la categor铆a:", options=list(categories.keys()))

    # Revisar si se seleccion贸 una nueva categor铆a
    if 'current_category' not in st.session_state or st.session_state['current_category'] != category:
        # Reiniciar el chat y cargar los datos correspondientes a la nueva categor铆a
        reiniciar_chat()

        # Cargar el archivo correspondiente basado en la categor铆a seleccionada
        dataframe = load_xlsx(categories[category])
        st.session_state['dataframe'] = dataframe  # Guardar el dataframe en la sesi贸n
        st.session_state['current_category'] = category  # Guardar la categor铆a seleccionada

        # Imprimir en consola el cambio de dataset
        print(f"Se ha cargado el dataset para la categor铆a '{category}' desde el archivo: {categories[category]}")

        # Mensaje de sistema (no se muestra en el chat, solo se usa para el modelo)
        promptSistema = f"""
        Eres un asistente de datos del departamento del Quind铆o, especializado en: {category}.
        Tu tarea es responder de manera directa y concisa, sin agregar informaci贸n innecesaria o redundante.
        Si la pregunta puede ser respondida con los datos cargados en el archivo, responde con esos datos. Si no, puedes usar tu conocimiento general.
        """
        st.session_state['messages'].append({"role": "system", "content": promptSistema})

    # Obtener el dataframe desde la sesi贸n
    dataframe = st.session_state.get('dataframe', None)

    # Funci贸n para enviar el mensaje
    def submit():
        user_input = st.session_state.user_input
        if user_input.lower() == 'salir':
            st.write("隆Gracias por chatear!")
            st.stop()

        # Procesar el query (convertir a min煤sculas y tokenizar)
        processed_query = process_query(user_input)

        # Buscar en los datos del archivo seleccionado primero
        if dataframe is not None:
            search_results = search_in_data(processed_query, dataframe)

            if search_results:
                # Si se encuentra informaci贸n relevante en los archivos, responder con los resultados
                response = f"Encontr茅 estos resultados en los datos del archivo:\n{search_results}"
                st.session_state['messages'].append({"role": "assistant", "content": response})
            else:
                # Si no se encuentra en los datos, pasar la consulta al modelo LLM
                st.session_state['messages'].append({"role": "user", "content": user_input})
                with st.spinner("Buscando informaci贸n..."):
                    ai_response = get_ai_response(st.session_state['messages'])
                    # Solo agregar la respuesta del modelo si no se encontr贸 nada en los datos
                    response = ai_response
                    st.session_state['messages'].append({"role": "assistant", "content": ai_response})
        else:
            response = "No se ha cargado ning煤n archivo para la categor铆a seleccionada."
            st.session_state['messages'].append({"role": "assistant", "content": response})

        # Limpiar la entrada del usuario
        st.session_state.user_input = ""

    # Mostrar mensajes anteriores
    for message in st.session_state['messages']:
        if message["role"] != "system":  # No mostrar el mensaje del sistema
            role = "T煤" if message["role"] == "user" else "Bot"
            icon = "" if message["role"] == "assistant" else ""
            st.write(f"**{role} {icon}:** {message['content']}")  # Mostrar 铆conos con el rol
    
    # Formulario de entrada de usuario
    with st.form(key='chat_form', clear_on_submit=True):
        st.text_input("T煤:", key="user_input")
        submit_button = st.form_submit_button(label='Enviar', on_click=submit)

# Ejecuci贸n principal
if __name__ == "__main__":
    chat()
